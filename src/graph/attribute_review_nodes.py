"""
å±æ€§åç§°ReviewèŠ‚ç‚¹æ¨¡å—
å®ç°å±æ€§å‘½åè§„èŒƒæ£€æŸ¥å’Œä¼˜åŒ–å»ºè®®
ç»“åˆEDWçŸ¥è¯†åº“å’Œå¤§æ¨¡å‹è¯„ä¼°
"""

import logging
import yaml
import os
import re
from typing import Dict, Any, List, Optional, Tuple
from langchain.schema.messages import HumanMessage, AIMessage
from langgraph.types import interrupt
from langgraph.graph import StateGraph, START, END

from src.models.states import EDWState
from src.agent.edw_agents import get_shared_llm

logger = logging.getLogger(__name__)


class AttributeNameReviewer:
    """å±æ€§åç§°è¯„å®¡å™¨"""
    
    def __init__(self):
        """åˆå§‹åŒ–çŸ¥è¯†åº“"""
        self.knowledge_base = self._load_knowledge_base()
        self.llm = get_shared_llm()
    
    def _load_knowledge_base(self) -> dict:
        """åŠ è½½EDWå±æ€§åç§°çŸ¥è¯†åº“"""
        try:
            knowledge_path = os.path.join(
                os.path.dirname(os.path.dirname(os.path.dirname(__file__))),
                'config', 'edw_attribute_knowledge.yaml'
            )
            
            with open(knowledge_path, 'r', encoding='utf-8') as f:
                knowledge = yaml.safe_load(f)
            
            logger.info(f"æˆåŠŸåŠ è½½EDWå±æ€§åç§°çŸ¥è¯†åº“ï¼ŒåŒ…å« {self._count_attributes(knowledge)} ä¸ªæ ‡å‡†å±æ€§")
            return knowledge
        except Exception as e:
            logger.error(f"åŠ è½½çŸ¥è¯†åº“å¤±è´¥: {e}")
            return {
                "naming_conventions": {},
                "common_attributes": {},
                "scoring_rules": {},
                "suggestion_rules": []
            }
    
    def _count_attributes(self, knowledge: dict) -> int:
        """ç»Ÿè®¡çŸ¥è¯†åº“ä¸­çš„å±æ€§æ•°é‡"""
        count = 0
        for category in knowledge.get("common_attributes", {}).values():
            if isinstance(category, list):
                count += len(category)
            elif isinstance(category, dict):
                for items in category.values():
                    if isinstance(items, list):
                        count += len(items)
        return count
    
    def review_attribute_name(self, physical_name: str, attribute_name: str, 
                             context: Optional[str] = None) -> dict:
        """
        è¯„å®¡å•ä¸ªå±æ€§åç§°
        
        Returns:
            dict: åŒ…å«scoreã€feedbackã€suggestionsç­‰
        """
        # 1. çŸ¥è¯†åº“åŒ¹é…
        kb_match = self._match_knowledge_base(physical_name, attribute_name)
        
        # 2. å‘½åè§„èŒƒæ£€æŸ¥
        convention_score = self._check_naming_convention(attribute_name)
        
        # 3. ä½¿ç”¨LLMæ·±åº¦è¯„ä¼°
        llm_evaluation = self._llm_evaluate(physical_name, attribute_name, context, kb_match)
        
        # 4. ç»¼åˆè¯„åˆ†
        final_score = self._calculate_final_score(kb_match, convention_score, llm_evaluation)
        
        # 5. ç”Ÿæˆå»ºè®®
        suggestions = self._generate_suggestions(
            physical_name, attribute_name, kb_match, convention_score, llm_evaluation
        )
        
        return {
            "physical_name": physical_name,
            "current_attribute_name": attribute_name,
            "score": final_score,
            "kb_match": kb_match,
            "convention_score": convention_score,
            "llm_evaluation": llm_evaluation,
            "suggestions": suggestions,
            "feedback": self._generate_feedback(final_score, kb_match, convention_score)
        }
    
    def _match_knowledge_base(self, physical_name: str, attribute_name: str) -> Optional[dict]:
        """åœ¨çŸ¥è¯†åº“ä¸­åŒ¹é…å±æ€§"""
        physical_lower = physical_name.lower()
        
        # éå†æ‰€æœ‰ç±»åˆ«
        for category_name, category_data in self.knowledge_base.get("common_attributes", {}).items():
            if isinstance(category_data, dict):
                # å¤„ç†åµŒå¥—ç»“æ„ï¼ˆå¦‚financeä¸‹çš„invoiceã€paymentç­‰ï¼‰
                for subcategory, items in category_data.items():
                    if isinstance(items, list):
                        for item in items:
                            if item.get("physical", "").lower() == physical_lower:
                                return {
                                    "category": f"{category_name}/{subcategory}",
                                    "standard_name": item.get("standard"),
                                    "chinese_name": item.get("chinese"),
                                    "kb_score": item.get("score", 90),
                                    "exact_match": True
                                }
            elif isinstance(category_data, list):
                # å¤„ç†ç›´æ¥åˆ—è¡¨ç»“æ„
                for item in category_data:
                    if item.get("physical", "").lower() == physical_lower:
                        return {
                            "category": category_name,
                            "standard_name": item.get("standard"),
                            "chinese_name": item.get("chinese"),
                            "kb_score": item.get("score", 90),
                            "exact_match": True
                        }
        
        # æ¨¡ç³ŠåŒ¹é…
        return self._fuzzy_match_knowledge_base(physical_name, attribute_name)
    
    def _fuzzy_match_knowledge_base(self, physical_name: str, attribute_name: str) -> Optional[dict]:
        """æ¨¡ç³ŠåŒ¹é…çŸ¥è¯†åº“"""
        physical_parts = set(physical_name.lower().split('_'))
        best_match = None
        best_score = 0
        
        for category_name, category_data in self.knowledge_base.get("common_attributes", {}).items():
            items_to_check = []
            
            if isinstance(category_data, dict):
                for subcategory, items in category_data.items():
                    if isinstance(items, list):
                        items_to_check.extend([(f"{category_name}/{subcategory}", item) for item in items])
            elif isinstance(category_data, list):
                items_to_check.extend([(category_name, item) for item in category_data])
            
            for category_path, item in items_to_check:
                item_parts = set(item.get("physical", "").lower().split('_'))
                overlap = len(physical_parts & item_parts)
                if overlap > 0:
                    score = overlap / max(len(physical_parts), len(item_parts))
                    if score > best_score:
                        best_score = score
                        best_match = {
                            "category": category_path,
                            "standard_name": item.get("standard"),
                            "chinese_name": item.get("chinese"),
                            "kb_score": item.get("score", 90) * score,
                            "exact_match": False,
                            "similarity": score
                        }
        
        return best_match if best_score > 0.5 else None
    
    def _check_naming_convention(self, attribute_name: str) -> dict:
        """æ£€æŸ¥å‘½åè§„èŒƒ"""
        score = 100
        issues = []
        
        # æ£€æŸ¥æ˜¯å¦æ˜¯å¸•æ–¯å¡å‘½åæ³•
        if re.match(r'^[A-Z][a-zA-Z0-9]*$', attribute_name):
            # æ£€æŸ¥æ¯ä¸ªå•è¯é¦–å­—æ¯æ˜¯å¦å¤§å†™
            if re.match(r'^([A-Z][a-z0-9]*)+$', attribute_name):
                score = 100
            else:
                score = 90
                issues.append("ä¸å®Œå…¨ç¬¦åˆå¸•æ–¯å¡å‘½åæ³•")
        # æ£€æŸ¥æ˜¯å¦æ˜¯é©¼å³°å‘½åæ³•
        elif re.match(r'^[a-z][a-zA-Z0-9]*$', attribute_name):
            score = 80
            issues.append("ä½¿ç”¨äº†é©¼å³°å‘½åæ³•è€Œéå¸•æ–¯å¡å‘½åæ³•")
        # æ£€æŸ¥æ˜¯å¦åŒ…å«ä¸‹åˆ’çº¿
        elif '_' in attribute_name:
            score = 60
            issues.append("åŒ…å«ä¸‹åˆ’çº¿ï¼Œåº”ä½¿ç”¨å¸•æ–¯å¡å‘½åæ³•")
        # æ£€æŸ¥æ˜¯å¦åŒ…å«è¿å­—ç¬¦
        elif '-' in attribute_name:
            score = 50
            issues.append("åŒ…å«è¿å­—ç¬¦ï¼Œåº”ä½¿ç”¨å¸•æ–¯å¡å‘½åæ³•")
        else:
            score = 70
            issues.append("å‘½åæ ¼å¼ä¸è§„èŒƒ")
        
        # æ£€æŸ¥é•¿åº¦
        if len(attribute_name) > 30:
            score -= 5
            issues.append("åç§°è¿‡é•¿")
        elif len(attribute_name) < 3:
            score -= 10
            issues.append("åç§°è¿‡çŸ­")
        
        # æ£€æŸ¥æ˜¯å¦ä½¿ç”¨ç¼©å†™
        common_abbreviations = ['no', 'num', 'id', 'cd', 'dt', 'amt', 'qty', 'desc']
        for abbr in common_abbreviations:
            if abbr in attribute_name.lower():
                score -= 5
                issues.append(f"å¯èƒ½ä½¿ç”¨äº†ç¼©å†™: {abbr}")
                break
        
        return {
            "score": max(score, 0),
            "issues": issues
        }
    
    def _llm_evaluate(self, physical_name: str, attribute_name: str, 
                     context: Optional[str], kb_match: Optional[dict]) -> dict:
        """ä½¿ç”¨LLMè¯„ä¼°å±æ€§åç§°"""
        try:
            prompt = f"""ä½ æ˜¯ä¸€ä¸ªEDWï¼ˆä¼ä¸šæ•°æ®ä»“åº“ï¼‰å±æ€§å‘½åä¸“å®¶ã€‚è¯·è¯„ä¼°ä»¥ä¸‹å±æ€§åç§°çš„è´¨é‡ã€‚

ç‰©ç†å­—æ®µå: {physical_name}
å½“å‰å±æ€§å: {attribute_name}
ä¸šåŠ¡ä¸Šä¸‹æ–‡: {context or 'æœªæä¾›'}
çŸ¥è¯†åº“åŒ¹é…: {kb_match.get('standard_name') if kb_match else 'æ— åŒ¹é…'}

è¯„ä¼°æ ‡å‡†ï¼š
1. æ¸…æ™°æ€§ï¼ˆ20åˆ†ï¼‰ï¼šåç§°æ˜¯å¦æ¸…æ™°è¡¨è¾¾ä¸šåŠ¡å«ä¹‰
2. è§„èŒƒæ€§ï¼ˆ20åˆ†ï¼‰ï¼šæ˜¯å¦ç¬¦åˆEDWå‘½åè§„èŒƒï¼ˆå¸•æ–¯å¡å‘½åæ³•ï¼‰
3. ä¸€è‡´æ€§ï¼ˆ20åˆ†ï¼‰ï¼šæ˜¯å¦ä¸EDWæ ‡å‡†ä¿æŒä¸€è‡´
4. å‡†ç¡®æ€§ï¼ˆ20åˆ†ï¼‰ï¼šæ˜¯å¦å‡†ç¡®åæ˜ å­—æ®µç”¨é€”
5. ç®€æ´æ€§ï¼ˆ20åˆ†ï¼‰ï¼šæ˜¯å¦ç®€æ´è€Œä¸å¤±å®Œæ•´

è¯·ç»™å‡ºï¼š
1. æ€»åˆ†ï¼ˆ0-100ï¼‰
2. ç®€çŸ­è¯„ä»·
3. æ”¹è¿›å»ºè®®ï¼ˆå¦‚æœ‰ï¼‰

è¾“å‡ºJSONæ ¼å¼ï¼š
{{
    "score": åˆ†æ•°,
    "evaluation": "è¯„ä»·",
    "suggestions": ["å»ºè®®1", "å»ºè®®2"],
    "recommended_name": "æ¨èçš„å±æ€§åç§°"
}}"""
            
            response = self.llm.invoke(prompt)
            content = response.content if hasattr(response, 'content') else str(response)
            
            # è§£æLLMå“åº”
            import json
            try:
                result = json.loads(content)
                return result
            except:
                # å¦‚æœè§£æå¤±è´¥ï¼Œå°è¯•æå–å…³é”®ä¿¡æ¯
                score_match = re.search(r'"score":\s*(\d+)', content)
                score = int(score_match.group(1)) if score_match else 70
                
                return {
                    "score": score,
                    "evaluation": "LLMè¯„ä¼°å®Œæˆ",
                    "suggestions": [],
                    "recommended_name": attribute_name
                }
                
        except Exception as e:
            logger.error(f"LLMè¯„ä¼°å¤±è´¥: {e}")
            return {
                "score": 70,
                "evaluation": "è¯„ä¼°å¤±è´¥ï¼Œä½¿ç”¨é»˜è®¤åˆ†æ•°",
                "suggestions": [],
                "recommended_name": attribute_name
            }
    
    def _calculate_final_score(self, kb_match: Optional[dict], 
                               convention_score: dict, llm_evaluation: dict) -> float:
        """è®¡ç®—æœ€ç»ˆè¯„åˆ†"""
        # æƒé‡åˆ†é…
        weights = {
            "kb": 0.4,      # çŸ¥è¯†åº“åŒ¹é…æƒé‡
            "convention": 0.3,  # å‘½åè§„èŒƒæƒé‡
            "llm": 0.3      # LLMè¯„ä¼°æƒé‡
        }
        
        kb_score = kb_match.get("kb_score", 60) if kb_match else 60
        conv_score = convention_score.get("score", 70)
        llm_score = llm_evaluation.get("score", 70)
        
        final_score = (
            kb_score * weights["kb"] +
            conv_score * weights["convention"] +
            llm_score * weights["llm"]
        )
        
        return round(final_score, 1)
    
    def _generate_suggestions(self, physical_name: str, attribute_name: str,
                             kb_match: Optional[dict], convention_score: dict,
                             llm_evaluation: dict) -> List[dict]:
        """ç”Ÿæˆæ”¹è¿›å»ºè®®"""
        suggestions = []
        
        # 1. çŸ¥è¯†åº“å»ºè®®
        if kb_match and kb_match.get("standard_name"):
            if kb_match["standard_name"] != attribute_name:
                suggestions.append({
                    "type": "knowledge_base",
                    "suggested_name": kb_match["standard_name"],
                    "reason": f"EDWæ ‡å‡†å‘½åï¼ˆ{kb_match.get('chinese_name', '')}ï¼‰",
                    "confidence": 0.95 if kb_match.get("exact_match") else 0.7
                })
        
        # 2. å‘½åè§„èŒƒå»ºè®®
        if convention_score["score"] < 90:
            # è½¬æ¢ä¸ºå¸•æ–¯å¡å‘½åæ³•
            pascal_name = self._to_pascal_case(attribute_name)
            if pascal_name != attribute_name:
                suggestions.append({
                    "type": "convention",
                    "suggested_name": pascal_name,
                    "reason": "è½¬æ¢ä¸ºå¸•æ–¯å¡å‘½åæ³•",
                    "confidence": 0.8
                })
        
        # 3. LLMå»ºè®®
        if llm_evaluation.get("recommended_name") and llm_evaluation["recommended_name"] != attribute_name:
            suggestions.append({
                "type": "llm",
                "suggested_name": llm_evaluation["recommended_name"],
                "reason": llm_evaluation.get("evaluation", "AIæ¨è"),
                "confidence": 0.85
            })
        
        # å»é‡å¹¶æ’åº
        seen_names = set()
        unique_suggestions = []
        for sugg in sorted(suggestions, key=lambda x: x["confidence"], reverse=True):
            if sugg["suggested_name"] not in seen_names:
                seen_names.add(sugg["suggested_name"])
                unique_suggestions.append(sugg)
        
        return unique_suggestions[:3]  # æœ€å¤šè¿”å›3ä¸ªå»ºè®®
    
    def _to_pascal_case(self, name: str) -> str:
        """è½¬æ¢ä¸ºå¸•æ–¯å¡å‘½åæ³•"""
        # å¤„ç†ä¸‹åˆ’çº¿å‘½å
        if '_' in name:
            parts = name.split('_')
            return ''.join(word.capitalize() for word in parts if word)
        # å¤„ç†è¿å­—ç¬¦å‘½å
        elif '-' in name:
            parts = name.split('-')
            return ''.join(word.capitalize() for word in parts if word)
        # å¤„ç†é©¼å³°å‘½åï¼ˆé¦–å­—æ¯å°å†™ï¼‰
        elif name and name[0].islower():
            return name[0].upper() + name[1:]
        # å·²ç»æ˜¯å¸•æ–¯å¡å‘½åæˆ–å…¶ä»–æƒ…å†µ
        return name
    
    def _generate_feedback(self, score: float, kb_match: Optional[dict], 
                          convention_score: dict) -> str:
        """ç”Ÿæˆåé¦ˆä¿¡æ¯"""
        if score >= 90:
            return "å±æ€§å‘½åä¼˜ç§€ï¼Œå®Œå…¨ç¬¦åˆEDWæ ‡å‡†"
        elif score >= 80:
            return "å±æ€§å‘½åè‰¯å¥½ï¼Œç•¥æœ‰æ”¹è¿›ç©ºé—´"
        elif score >= 70:
            return "å±æ€§å‘½ååˆæ ¼ï¼Œå»ºè®®é‡‡çº³æ”¹è¿›å»ºè®®"
        elif score >= 60:
            return "å±æ€§å‘½åéœ€è¦æ”¹è¿›ï¼Œè¯·è€ƒè™‘ä½¿ç”¨æ¨èçš„å‘½å"
        else:
            return "å±æ€§å‘½åä¸ç¬¦åˆè§„èŒƒï¼Œå¼ºçƒˆå»ºè®®ä¿®æ”¹"


def attribute_review_node(state: EDWState) -> dict:
    """
    å±æ€§åç§°reviewèŠ‚ç‚¹
    è¯„ä¼°æ‰€æœ‰å­—æ®µçš„å±æ€§å‘½åå¹¶ç»™å‡ºå»ºè®®
    """
    try:
        fields = state.get("fields", [])
        table_name = state.get("table_name", "")
        logic_detail = state.get("logic_detail", "")
        user_id = state.get("user_id", "")
        
        if not fields:
            logger.info("æ²¡æœ‰éœ€è¦reviewçš„å­—æ®µ")
            return {
                "attribute_review_completed": True,
                "user_id": user_id
            }
        
        # åˆ›å»ºè¯„å®¡å™¨
        reviewer = AttributeNameReviewer()
        
        # è¯„å®¡æ‰€æœ‰å­—æ®µ
        review_results = []
        total_score = 0
        needs_improvement = []
        
        for field in fields:
            if isinstance(field, dict):
                physical_name = field.get('physical_name', '')
                attribute_name = field.get('attribute_name', '')
            else:
                physical_name = getattr(field, 'physical_name', '')
                attribute_name = getattr(field, 'attribute_name', '')
            
            if physical_name and attribute_name:
                # è¯„å®¡å•ä¸ªå±æ€§
                result = reviewer.review_attribute_name(
                    physical_name=physical_name,
                    attribute_name=attribute_name,
                    context=f"è¡¨: {table_name}, é€»è¾‘: {logic_detail}"
                )
                
                review_results.append(result)
                total_score += result["score"]
                
                # å¦‚æœè¯„åˆ†ä½äº80ï¼Œéœ€è¦æ”¹è¿›
                if result["score"] < 80 and result["suggestions"]:
                    needs_improvement.append({
                        "field": physical_name,
                        "current": attribute_name,
                        "suggestions": result["suggestions"],
                        "score": result["score"]
                    })
                
                logger.info(f"å±æ€§review - {physical_name}: {attribute_name} -> è¯„åˆ†: {result['score']}")
        
        # è®¡ç®—å¹³å‡åˆ†
        avg_score = total_score / len(review_results) if review_results else 100
        
        # å¦‚æœæœ‰éœ€è¦æ”¹è¿›çš„å±æ€§ï¼Œè§¦å‘ä¸­æ–­è®©ç”¨æˆ·ç¡®è®¤
        if needs_improvement:
            logger.info(f"å‘ç° {len(needs_improvement)} ä¸ªå±æ€§éœ€è¦æ”¹è¿›ï¼Œè§¦å‘ä¸­æ–­è¯¢é—®ç”¨æˆ·")
            
            # æ„å»ºæ”¹è¿›å»ºè®®æç¤º
            improvement_prompt = _build_improvement_prompt(needs_improvement, avg_score)
            
            # ä½¿ç”¨ä¸­æ–­æœºåˆ¶è®©ç”¨æˆ·ç¡®è®¤
            user_response = interrupt({
                "prompt": improvement_prompt,
                "action_type": "attribute_improvement",
                "needs_improvement": needs_improvement
            })
            
            # å¤„ç†ç”¨æˆ·å“åº”
            return _process_user_response(state, user_response, needs_improvement, review_results)
        
        # æ‰€æœ‰å±æ€§éƒ½åˆæ ¼ï¼Œç»§ç»­æµç¨‹
        logger.info(f"æ‰€æœ‰å±æ€§å‘½ååˆæ ¼ï¼Œå¹³å‡åˆ†: {avg_score}")
        
        return {
            "attribute_review_completed": True,
            "attribute_review_results": review_results,
            "attribute_avg_score": avg_score,
            "user_id": user_id
        }
        
    except Exception as e:
        logger.error(f"å±æ€§reviewèŠ‚ç‚¹å¤±è´¥: {e}")
        return {
            "attribute_review_completed": True,
            "error_message": str(e),
            "user_id": state.get("user_id", "")
        }


def _build_improvement_prompt(needs_improvement: List[dict], avg_score: float) -> str:
    """æ„å»ºæ”¹è¿›å»ºè®®æç¤º"""
    prompt = f"""## ğŸ“ å±æ€§å‘½åReviewç»“æœ

**å¹³å‡è¯„åˆ†**: {avg_score:.1f}/100

å‘ç°ä»¥ä¸‹å±æ€§å‘½åå¯ä»¥æ”¹è¿›ï¼š

"""
    
    for item in needs_improvement:
        prompt += f"\n### å­—æ®µ: {item['field']}\n"
        prompt += f"- **å½“å‰åç§°**: {item['current']} (è¯„åˆ†: {item['score']:.1f})\n"
        prompt += f"- **å»ºè®®æ”¹è¿›**:\n"
        
        for i, sugg in enumerate(item['suggestions'][:3], 1):
            prompt += f"  {i}. **{sugg['suggested_name']}** - {sugg['reason']}\n"
    
    prompt += """
**è¯·é€‰æ‹©**ï¼š
1. è¾“å…¥ 'accept' æˆ– 'æ¥å—' - é‡‡çº³æ‰€æœ‰ç¬¬ä¸€æ¨è
2. è¾“å…¥ 'skip' æˆ– 'è·³è¿‡' - ä¿æŒåŸæœ‰å‘½å
3. è¾“å…¥è‡ªå®šä¹‰é€‰æ‹©ï¼Œæ ¼å¼: field1:2,field2:1 (ä¸ºæ¯ä¸ªå­—æ®µé€‰æ‹©ç¬¬Nä¸ªå»ºè®®)
4. ç›´æ¥è¾“å…¥æ–°çš„å‘½åï¼Œæ ¼å¼: field1:NewName,field2:AnotherName

æ‚¨çš„é€‰æ‹©ï¼š"""
    
    return prompt


def _process_user_response(state: EDWState, user_response: str, 
                           needs_improvement: List[dict], 
                           review_results: List[dict]) -> dict:
    """å¤„ç†ç”¨æˆ·å¯¹å±æ€§æ”¹è¿›å»ºè®®çš„å“åº”"""
    
    user_id = state.get("user_id", "")
    fields = state.get("fields", [])
    
    # è§£æç”¨æˆ·å“åº”
    response_lower = user_response.lower().strip()
    
    if response_lower in ['accept', 'æ¥å—', 'yes', 'æ˜¯']:
        # é‡‡çº³æ‰€æœ‰ç¬¬ä¸€æ¨è
        logger.info("ç”¨æˆ·é€‰æ‹©é‡‡çº³æ‰€æœ‰ç¬¬ä¸€æ¨è")
        updated_fields = _apply_first_suggestions(fields, needs_improvement)
        
        return {
            "fields": updated_fields,
            "attribute_review_completed": True,
            "attribute_improvements_applied": True,
            "attribute_review_results": review_results,
            "user_id": user_id,
            "messages": [AIMessage(content="å·²é‡‡çº³æ‰€æœ‰å±æ€§å‘½åæ”¹è¿›å»ºè®®")]
        }
    
    elif response_lower in ['skip', 'è·³è¿‡', 'no', 'å¦']:
        # ä¿æŒåŸæœ‰å‘½å
        logger.info("ç”¨æˆ·é€‰æ‹©ä¿æŒåŸæœ‰å‘½å")
        
        return {
            "attribute_review_completed": True,
            "attribute_improvements_applied": False,
            "attribute_review_results": review_results,
            "user_id": user_id,
            "messages": [AIMessage(content="ä¿æŒåŸæœ‰å±æ€§å‘½å")]
        }
    
    else:
        # è§£æè‡ªå®šä¹‰é€‰æ‹©
        logger.info(f"è§£æç”¨æˆ·è‡ªå®šä¹‰é€‰æ‹©: {user_response}")
        updated_fields = _apply_custom_selections(fields, needs_improvement, user_response)
        
        return {
            "fields": updated_fields,
            "attribute_review_completed": True,
            "attribute_improvements_applied": True,
            "attribute_review_results": review_results,
            "user_id": user_id,
            "messages": [AIMessage(content=f"å·²åº”ç”¨è‡ªå®šä¹‰å±æ€§å‘½å: {user_response}")]
        }


def _apply_first_suggestions(fields: List[dict], needs_improvement: List[dict]) -> List[dict]:
    """åº”ç”¨ç¬¬ä¸€æ¨èçš„å±æ€§åç§°"""
    # åˆ›å»ºæ˜ å°„è¡¨
    improvement_map = {}
    for item in needs_improvement:
        if item["suggestions"]:
            improvement_map[item["field"]] = item["suggestions"][0]["suggested_name"]
    
    # æ›´æ–°å­—æ®µ
    updated_fields = []
    for field in fields:
        field_copy = field.copy() if isinstance(field, dict) else field.__dict__.copy()
        
        physical_name = field_copy.get('physical_name', '')
        if physical_name in improvement_map:
            field_copy['attribute_name'] = improvement_map[physical_name]
            logger.info(f"æ›´æ–°å±æ€§åç§°: {physical_name} -> {improvement_map[physical_name]}")
        
        updated_fields.append(field_copy)
    
    return updated_fields


def _apply_custom_selections(fields: List[dict], needs_improvement: List[dict], 
                            user_response: str) -> List[dict]:
    """åº”ç”¨ç”¨æˆ·è‡ªå®šä¹‰é€‰æ‹©"""
    # è§£æç”¨æˆ·è¾“å…¥
    selections = {}
    for part in user_response.split(','):
        part = part.strip()
        if ':' in part:
            field_name, choice = part.split(':', 1)
            field_name = field_name.strip()
            choice = choice.strip()
            
            # æ£€æŸ¥æ˜¯å¦æ˜¯æ•°å­—ï¼ˆé€‰æ‹©ç¬¬Nä¸ªå»ºè®®ï¼‰
            if choice.isdigit():
                choice_idx = int(choice) - 1
                # æŸ¥æ‰¾å¯¹åº”çš„å»ºè®®
                for item in needs_improvement:
                    if item["field"] == field_name and 0 <= choice_idx < len(item["suggestions"]):
                        selections[field_name] = item["suggestions"][choice_idx]["suggested_name"]
                        break
            else:
                # ç›´æ¥ä½¿ç”¨ç”¨æˆ·è¾“å…¥çš„åç§°
                selections[field_name] = choice
    
    # æ›´æ–°å­—æ®µ
    updated_fields = []
    for field in fields:
        field_copy = field.copy() if isinstance(field, dict) else field.__dict__.copy()
        
        physical_name = field_copy.get('physical_name', '')
        if physical_name in selections:
            field_copy['attribute_name'] = selections[physical_name]
            logger.info(f"æ›´æ–°å±æ€§åç§°: {physical_name} -> {selections[physical_name]}")
        
        updated_fields.append(field_copy)
    
    return updated_fields


def create_attribute_review_subgraph():
    """
    åˆ›å»ºå±æ€§åç§°reviewå­å›¾
    """
    from src.agent.edw_agents import get_shared_checkpointer
    
    logger.info("åˆ›å»ºå±æ€§åç§°reviewå­å›¾")
    
    return (
        StateGraph(EDWState)
        .add_node("attribute_review", attribute_review_node)
        .add_edge(START, "attribute_review")
        .add_edge("attribute_review", END)
        .compile(checkpointer=get_shared_checkpointer())
    )